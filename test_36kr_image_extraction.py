#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•36krç½‘ç«™image-wrapperå›¾ç‰‡æå–åŠŸèƒ½
æ³¨æ„ï¼š36krçš„å›¾ç‰‡ç»“æ„æ˜¯ <p class="image-wrapper"><img ...></p>
"""

import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from services.crawler_service import CrawlerService
import asyncio

async def test_36kr_image_extraction():
    """æµ‹è¯•36krå›¾ç‰‡æå–"""
    # ä½¿ç”¨ä¸€ä¸ªçœŸå®çš„36kræ–‡ç« URLè¿›è¡Œæµ‹è¯•
    test_url = "https://www.36kr.com/p/3678583640810112"  # å¯ä»¥æ›¿æ¢ä¸ºå…¶ä»–36kræ–‡ç« URL
    
    print("ğŸ” æµ‹è¯•36krç½‘ç«™image-wrapperå›¾ç‰‡æå–åŠŸèƒ½")
    print("=" * 60)
    
    try:
        # 1. è·å–é¡µé¢å†…å®¹
        print("ğŸ“¥ æ­£åœ¨è·å–é¡µé¢å†…å®¹...")
        html, title = await CrawlerService.get_page_content(test_url)
        print(f"ğŸ“„ é¡µé¢æ ‡é¢˜: {title}")
        
        # 2. æå–å†…å®¹å’Œå›¾ç‰‡
        print("\nğŸ–¼ï¸  æ­£åœ¨æå–å›¾ç‰‡...")
        result = CrawlerService.extract_content(html, test_url)
        
        print(f"ğŸ“ å†…å®¹é•¿åº¦: {len(result['content'])} å­—ç¬¦")
        print(f"ğŸ“Š æ€»å›¾ç‰‡æ•°é‡: {len(result['images'])} å¼ ")
        
        # 3. åˆ†ç±»ç»Ÿè®¡
        image_wrapper_count = 0
        other_count = 0
        
        for img in result['images']:
            if img.get('class') == 'image-wrapper':
                image_wrapper_count += 1
                print(f"ğŸ¯ å‘ç°image-wrapperå›¾ç‰‡: {img['url']}")
            else:
                other_count += 1
        
        print(f"\nğŸ“ˆ æå–ç»Ÿè®¡:")
        print(f"   image-wrapperå®¹å™¨ä¸­çš„å›¾ç‰‡: {image_wrapper_count} å¼ ")
        print(f"   å…¶ä»–å›¾ç‰‡: {other_count} å¼ ")
        print(f"   æ€»è®¡: {len(result['images'])} å¼ ")
        
        # 4. æ˜¾ç¤ºå‰å‡ å¼ å›¾ç‰‡URL
        print(f"\nğŸ“‹ å‰5å¼ å›¾ç‰‡URL:")
        for i, img in enumerate(result['images'][:5]):
            source_class = img.get('class', 'unknown')
            container_info = img.get('container', '')
            container_text = f" [{container_info}]" if container_info else ""
            print(f"   {i+1}. [{source_class}]{container_text} {img['url']}")
            
        if len(result['images']) > 5:
            print(f"   ... è¿˜æœ‰ {len(result['images']) - 5} å¼ å›¾ç‰‡")
            
        # 5. éªŒè¯æ˜¯å¦åªæå–äº†image-wrapperä¸­çš„å›¾ç‰‡
        if image_wrapper_count > 0 and other_count == 0:
            print(f"\nâœ… æˆåŠŸï¼åªæå–äº†image-wrapperå®¹å™¨ä¸­çš„å›¾ç‰‡")
        elif image_wrapper_count > 0 and other_count > 0:
            print(f"\nâš ï¸  æ³¨æ„ï¼šæå–åˆ°äº†{image_wrapper_count}å¼ image-wrapperå›¾ç‰‡å’Œ{other_count}å¼ å…¶ä»–å›¾ç‰‡")
        else:
            print(f"\nâŒ æœªæ‰¾åˆ°ä»»ä½•image-wrapperå›¾ç‰‡")
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(test_36kr_image_extraction())