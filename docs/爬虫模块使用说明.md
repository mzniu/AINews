# 爬虫模块使用说明

## ✅ 已完成功能

1. **基础框架**
   - 爬虫基类 `BaseCrawler`
   - 数据模型 `Article`
   - 日志系统（Loguru）
   - 配置管理
   - 去重机制（URL哈希）

2. **机器之心爬虫**
   - `JiqizhixinCrawler` 类实现
   - 列表页解析
   - 详情页解析
   - 数据保存为JSON

3. **工具脚本**
   - `scripts/run_crawler.py` - 运行爬虫
   - `scripts/generate_mock_data.py` - 生成测试数据

## 📦 已安装依赖

```
requests       - HTTP请求
beautifulsoup4 - HTML解析
lxml           - 解析器
pydantic       - 数据验证
loguru         - 日志系统
python-dotenv  - 环境变量
pyyaml         - YAML配置
rich           - 终端美化
click          - CLI工具
```

## 🚀 使用方法

### 1. 生成测试数据

由于网络环境原因，先使用模拟数据进行开发：

```bash
.\.venv\Scripts\python.exe scripts\generate_mock_data.py
```

生成的数据位于：`data/raw/jiqizhixin/mock_articles.json`

### 2. 查看模拟数据

```bash
type data\raw\jiqizhixin\mock_articles.json
```

### 3. 运行爬虫（需要网络环境支持）

```bash
# 批量爬取
.\.venv\Scripts\python.exe scripts\run_crawler.py --source jiqizhixin --max-articles 5

# 测试单个URL
.\.venv\Scripts\python.exe scripts\run_crawler.py --source jiqizhixin --test-url "https://www.jiqizhixin.com/articles/2026-02-05-1"
```

## 📊 数据结构

每篇文章包含以下字段：

```python
{
    "id": "文章唯一ID（URL哈希）",
    "title": "文章标题",
    "url": "文章URL",
    "source": "来源网站",
    "author": "作者",
    "publish_time": "发布时间",
    "content": "正文内容",
    "summary": "摘要",
    "tags": ["标签1", "标签2"],
    "images": ["图片URL1", "图片URL2"],
    "crawl_time": "爬取时间",
    "status": "状态（pending/processed/published）"
}
```

## 🔧 爬虫工作流程

```
1. 访问列表页
   ↓
2. 提取文章链接（去重）
   ↓
3. 访问每篇文章详情页
   ↓
4. 提取标题、作者、时间、正文等
   ↓
5. 保存到JSON文件
```

## ⚠️ 当前限制

1. **网络访问问题**
   - 机器之心网站可能需要代理访问
   - 可能使用JavaScript动态加载内容
   
2. **解决方案**
   - 使用Selenium进行动态页面爬取
   - 配置代理
   - 先使用模拟数据开发其他模块

## 📝 后续计划

1. **爬虫增强**
   - [ ] 添加Selenium支持（处理动态页面）
   - [ ] 实现代理池
   - [ ] 添加更多爬虫源（量子位、AI科技评论等）
   - [ ] 实现Redis去重
   
2. **数据处理**
   - [ ] 集成DeepSeek API
   - [ ] 实现文章总结功能
   - [ ] 生成视频脚本

3. **视频生成**
   - [ ] TTS语音合成
   - [ ] 字幕生成
   - [ ] 视频合成

## 🎯 下一步建议

由于网络环境限制，建议：

1. **先开发DeepSeek总结模块**
   - 使用模拟数据作为输入
   - 测试API调用
   - 优化Prompt

2. **开发视频生成模块**
   - TTS测试
   - 字幕样式设计
   - 视频模板开发

3. **完善爬虫**
   - 配置合适的网络环境
   - 测试实际爬取
   - 增加更多数据源

## 📖 相关文档

- [爬虫设计文档](../docs/03-爬虫设计.md)
- [架构设计文档](../docs/02-架构设计.md)
- [项目概述](../docs/01-项目概述.md)
