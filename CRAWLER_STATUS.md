# çˆ¬è™«å¼€å‘æ€»ç»“ - çœŸå®çˆ¬å–ç‰ˆæœ¬

## âœ… å·²å®Œæˆçš„å·¥ä½œ

### 1. çˆ¬è™«åŸºç¡€æ¡†æ¶å¢å¼º
- **URLå»é‡æœºåˆ¶**: ä½¿ç”¨MD5å“ˆå¸Œ
- **é”™è¯¯å¤„ç†**: è¶…æ—¶ã€è¿æ¥é”™è¯¯åˆ†ç±»å¤„ç†
- **Seleniumæ”¯æŒ**: å¤„ç†JavaScriptæ¸²æŸ“é¡µé¢
- **ä»£ç†æ”¯æŒ**: å¯é…ç½®HTTP/HTTPSä»£ç†
- **å»¶è¿Ÿæ§åˆ¶**: é˜²æ­¢è¢«å°ç¦

### 2. å®ç°çš„çˆ¬è™«

#### æœºå™¨ä¹‹å¿ƒçˆ¬è™« (jiqizhixin.py)
- âœ… åˆ—è¡¨é¡µè§£æé€»è¾‘
- âœ… è¯¦æƒ…é¡µè§£æï¼ˆæ ‡é¢˜ã€ä½œè€…ã€æ—¶é—´ã€æ­£æ–‡ã€å›¾ç‰‡ã€æ ‡ç­¾ï¼‰
- âœ… å¤šç§é€‰æ‹©å™¨ç­–ç•¥
- âš ï¸ éœ€è¦ä»£ç†è®¿é—®

#### ç™¾åº¦æ–°é—»AIçˆ¬è™« (baidu_news.py)
- âœ… æœç´¢AIç›¸å…³æ–°é—»
- âœ… é€šç”¨æ–°é—»é¡µé¢è§£æ
- âœ… æ— éœ€ä»£ç†å³å¯è®¿é—®

#### 36æ°ªAIçˆ¬è™« (kr36_ai.py)
- âœ… AIé¢‘é“æ–‡ç« çˆ¬å–
- âœ… å®Œæ•´çš„è§£æé€»è¾‘

### 3. æµ‹è¯•å’Œå·¥å…·
- **test_jiqizhixin.py**: æ™ºèƒ½æ£€æµ‹ç½‘ç»œé—®é¢˜
- **test_rss.py**: RSSè®¢é˜…æºè·å–
- **find_working_sites.py**: æŸ¥æ‰¾å¯ç”¨ç½‘ç«™
- **check_website.py**: åˆ†æé¡µé¢ç»“æ„

## ğŸ”§ ç½‘ç»œé—®é¢˜è¯Šæ–­

### å½“å‰çŠ¶æ€
```
æµ‹è¯•æœºå™¨ä¹‹å¿ƒ: https://www.jiqizhixin.com
âŒ è¿æ¥è¶…æ—¶ï¼ˆ5ç§’ï¼‰
åŸå› : ç½‘ç»œç¯å¢ƒé™åˆ¶æˆ–éœ€è¦ä»£ç†
```

### è§£å†³æ–¹æ¡ˆï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰

#### æ–¹æ¡ˆ1: é…ç½®ä»£ç† â­ æ¨è
```bash
# .envæ–‡ä»¶
HTTP_PROXY=http://127.0.0.1:7890
HTTPS_PROXY=http://127.0.0.1:7890
```

ç„¶åä¿®æ”¹ `src/crawlers/base.py`ï¼š
```python
# åœ¨__init__æ–¹æ³•ä¸­æ·»åŠ 
if os.getenv('HTTP_PROXY'):
    proxies = {
        'http': os.getenv('HTTP_PROXY'),
        'https': os.getenv('HTTPS_PROXY'),
    }
    self.session.proxies.update(proxies)
```

#### æ–¹æ¡ˆ2: ä½¿ç”¨Selenium
```bash
pip install selenium webdriver-manager
```

```python
# ä½¿ç”¨æ–¹å¼
html = crawler.fetch_page(url, use_selenium=True)
```

#### æ–¹æ¡ˆ3: ä½¿ç”¨å¤‡ç”¨æ•°æ®æº
```bash
# ç™¾åº¦æ–°é—»ï¼ˆæ— éœ€ä»£ç†ï¼‰
python src/crawlers/baidu_news.py

# RSSæºï¼ˆå¯èƒ½éœ€è¦ä»£ç†ï¼‰
python test_rss.py
```

## ğŸ“ ä½¿ç”¨æŒ‡å—

### å¿«é€Ÿå¼€å§‹

#### 1. æµ‹è¯•ç½‘ç»œè¿æ¥
```bash
.\.venv\Scripts\python.exe test_jiqizhixin.py
```

#### 2. å¦‚æœæœ‰ä»£ç†å·¥å…·ï¼ˆClash/V2Rayï¼‰

**æ­¥éª¤1**: å¤åˆ¶ç¯å¢ƒå˜é‡
```bash
copy .env.example .env
```

**æ­¥éª¤2**: ç¼–è¾‘ `.env`ï¼Œæ·»åŠ ä»£ç†é…ç½®
```
HTTP_PROXY=http://127.0.0.1:7890
HTTPS_PROXY=http://127.0.0.1:7890
```

**æ­¥éª¤3**: ä¿®æ”¹ `src/crawlers/base.py` å¯ç”¨ä»£ç†æ”¯æŒ

**æ­¥éª¤4**: é‡æ–°æµ‹è¯•
```bash
.\.venv\Scripts\python.exe test_jiqizhixin.py
```

#### 3. å¦‚æœæ²¡æœ‰ä»£ç†å·¥å…·

ä½¿ç”¨å¤‡ç”¨çˆ¬è™«ï¼š
```bash
.\.venv\Scripts\python.exe src/crawlers/baidu_news.py
```

### æ·»åŠ ä»£ç†æ”¯æŒï¼ˆä»£ç ç¤ºä¾‹ï¼‰

åœ¨ `src/crawlers/base.py` çš„ `__init__` æ–¹æ³•ä¸­æ·»åŠ ï¼š

```python
import os
from dotenv import load_dotenv

class BaseCrawler(ABC):
    def __init__(self, source_name: str):
        load_dotenv()  # åŠ è½½ç¯å¢ƒå˜é‡
        
        self.source_name = source_name
        self.session = requests.Session()
        
        # é…ç½®ä»£ç†
        http_proxy = os.getenv('HTTP_PROXY')
        https_proxy = os.getenv('HTTPS_PROXY')
        
        if http_proxy and https_proxy:
            proxies = {
                'http': http_proxy,
                'https': https_proxy,
            }
            self.session.proxies.update(proxies)
            logger.info(f"ä½¿ç”¨ä»£ç†: {http_proxy}")
        
        self.session.headers.update({
            'User-Agent': Config.USER_AGENT
        })
        self.crawled_urls = set()
```

## ğŸ¯ ä¸‹ä¸€æ­¥è¡ŒåŠ¨

1. **å¦‚æœä½ æœ‰ä»£ç†**:
   - é…ç½®ä»£ç†åæµ‹è¯•æœºå™¨ä¹‹å¿ƒçˆ¬è™«
   - æˆåŠŸåç»§ç»­å¼€å‘å…¶ä»–çˆ¬è™«æº

2. **å¦‚æœæ²¡æœ‰ä»£ç†**:
   - ä½¿ç”¨ç™¾åº¦æ–°é—»çˆ¬è™«è·å–æ•°æ®
   - ç»§ç»­å¼€å‘DeepSeekå¤„ç†æ¨¡å—
   - ä½¿ç”¨çˆ¬å–çš„æ•°æ®æµ‹è¯•åç»­åŠŸèƒ½

3. **ç»§ç»­å¼€å‘å…¶ä»–æ¨¡å—**:
   - DeepSeek APIé›†æˆ
   - æ–‡ç« æ€»ç»“åŠŸèƒ½
   - è§†é¢‘ç”Ÿæˆæ¨¡å—

## ğŸ“Š æ•°æ®è·å–çŠ¶æ€

| æ•°æ®æº | çŠ¶æ€ | æ˜¯å¦éœ€è¦ä»£ç† | å¤‡æ³¨ |
|--------|------|-------------|------|
| æœºå™¨ä¹‹å¿ƒ | â¸ï¸ æš‚åœ | âœ… æ˜¯ | éœ€é…ç½®ä»£ç† |
| ç™¾åº¦æ–°é—» | âœ… å¯ç”¨ | âŒ å¦ | å¤‡ç”¨æ–¹æ¡ˆ |
| RSSè®¢é˜… | âš ï¸ éƒ¨åˆ†å¯ç”¨ | âš ï¸ éƒ¨åˆ†éœ€è¦ | å–å†³äºæº |
| 36æ°ªAI | âš ï¸ æœªæµ‹è¯• | âŒ å¦ | éœ€éªŒè¯ |

## ğŸ’¾ å·²æœ‰æ•°æ®

è™½ç„¶å®æ—¶çˆ¬å–å—é™ï¼Œä½†æˆ‘ä»¬æœ‰ï¼š
- âœ… å®Œæ•´çš„çˆ¬è™«æ¡†æ¶
- âœ… å¤šä¸ªçˆ¬è™«å®ç°
- âœ… é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶
- âœ… æ•°æ®æ¨¡å‹å’Œå­˜å‚¨

ä¸€æ—¦é…ç½®ä»£ç†æˆ–ç½‘ç»œç¯å¢ƒæ”¹å–„ï¼Œå³å¯ç«‹å³å¼€å§‹çœŸå®çˆ¬å–ã€‚

## ğŸ” è¯Šæ–­å‘½ä»¤

```bash
# æµ‹è¯•ç½‘ç»œè¿æ¥
.\.venv\Scripts\python.exe quick_test.py

# æŸ¥æ‰¾å¯ç”¨ç½‘ç«™
.\.venv\Scripts\python.exe find_working_sites.py

# æµ‹è¯•æœºå™¨ä¹‹å¿ƒ
.\.venv\Scripts\python.exe test_jiqizhixin.py

# æµ‹è¯•ç™¾åº¦æ–°é—»
.\.venv\Scripts\python.exe src\crawlers\baidu_news.py
```

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [çˆ¬è™«ç½‘ç»œé—®é¢˜è§£å†³æ–¹æ¡ˆ](docs/çˆ¬è™«ç½‘ç»œé—®é¢˜è§£å†³æ–¹æ¡ˆ.md)
- [çˆ¬è™«è®¾è®¡æ–‡æ¡£](docs/03-çˆ¬è™«è®¾è®¡.md)
- [é¡¹ç›®è¿›åº¦](PROJECT_STATUS.md)
